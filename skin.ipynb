{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hybrid18581/Pinball/blob/master/skin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bglGZTW1NSRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fd6a166d-11f4-4b47-b486-6d0ad5e80017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "V24YLMMANeBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d8a7eeb3-2ec1-4f93-d21a-e2e6194f80f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20231021_090717315_iOS.heic\n",
            " 20231021_090807040_iOS.heic\n",
            " 20231021_101234649_iOS.heic\n",
            " 20231021_101238438_iOS.heic\n",
            " 20231021_101929279_iOS.heic\n",
            " 688363e824201cc92596e7bc2d31891c2dd8c878c4c6bf65109528c861f869a4.pdf\n",
            " A96F388ADF040024B6A402B00_copy.pdf\n",
            "'Acct Statement_XX2041_07052025.pdf'\n",
            "'Colab Notebooks'\n",
            " EAadhaar_2836072801275420191213122602_14112022215234-1.pdf\n",
            " id_docs.pdf\n",
            "'images (8).jpeg'\n",
            "'IMG_20250822_093546_344_AI (1).jpg'\n",
            " IMG_20250822_093546_344_AI.jpg\n",
            " IMG-20250822-WA0004.jpg\n",
            " IMG_2494.HEIC\n",
            " IMG_2495.HEIC\n",
            " IMG_2500.HEIC\n",
            " IMG_2501.HEIC\n",
            " IMG_2502.HEIC\n",
            " IMG_2503.HEIC\n",
            " IMG_2504.HEIC\n",
            " IMG_2505.HEIC\n",
            " IMG_2506.HEIC\n",
            " IMG_2507.HEIC\n",
            " Leaderboard.gsheet\n",
            "'Meteora POC (version 2) (1).xlsx'\n",
            "'Meteora POC (version 2).xlsx'\n",
            "'Meteora Pricing.gsheet'\n",
            " models\n",
            " Netflix_datavisualisation_Sidhanth.pdf\n",
            "'New Microsoft Word Document.docx'\n",
            " payment_confirmation_202508234-095358.png\n",
            "'Resume_ds (1).pdf'\n",
            "'Resume_ds (2).pdf'\n",
            "'Resume_ds (3).pdf'\n",
            "'Resume_ds (4).pdf'\n",
            " resume_ds.pdf\n",
            " Resume_ds.pdf\n",
            " Resume_Sidhanth.pdf\n",
            " ResumeSidhanth.pdf\n",
            " ResumeSidhant.pdf\n",
            " Screenshot_20250822-192942.png\n",
            " Skin_Disease_Dataset.zip\n",
            " STPP-Prospectus_copy.pdf\n",
            "'WhatsApp Chat - Meteora.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Skin_Disease_Dataset.zip\" /content/"
      ],
      "metadata": {
        "id": "F7cLLtI-Ngpj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/Skin_Disease_Dataset.zip\" -d /content/skin_dataset"
      ],
      "metadata": {
        "id": "gGG0OmIcNjTZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/skin_dataset/skin Disease Dataset/kaggle\""
      ],
      "metadata": {
        "id": "1cClRMPANl5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d4d76a06-4e2f-4d76-f64a-8ce3c9a54a94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/skin_dataset/skin Disease Dataset/kaggle/train\"\n",
        "val_path   = \"/content/skin_dataset/skin Disease Dataset/kaggle/val\"\n",
        "test_path  = \"/content/skin_dataset/skin Disease Dataset/kaggle/test\""
      ],
      "metadata": {
        "id": "gNP8vuX1Noa2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.amp import autocast, GradScaler"
      ],
      "metadata": {
        "id": "8lpqYBVJNq-e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/models"
      ],
      "metadata": {
        "id": "OQLfZBEVNuPB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "SAMPLES_PER_CLASS = 3000\n",
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/train\")\n",
        "targets = np.array(train_dataset.targets)\n",
        "\n",
        "balanced_dir = \"/content/skin_dataset/skin Disease Dataset/kaggle/train_balanced\"\n",
        "os.makedirs(balanced_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(balanced_dir):\n",
        "    shutil.rmtree(balanced_dir)\n",
        "\n",
        "os.makedirs(balanced_dir)\n",
        "\n",
        "for cls in range(NUM_CLASSES):\n",
        "    cls_indices = np.where(targets == cls)[0]\n",
        "    selected = np.random.choice(cls_indices, SAMPLES_PER_CLASS, replace=len(cls_indices)<SAMPLES_PER_CLASS)\n",
        "\n",
        "    class_dir = os.path.join(balanced_dir, train_dataset.classes[cls])\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for j, idx in enumerate(selected):\n",
        "     src_path = train_dataset.imgs[idx][0]\n",
        "\n",
        "     filename = f\"{j}_{os.path.basename(src_path)}\"\n",
        "     dst_path = os.path.join(class_dir, filename)\n",
        "\n",
        "     shutil.copy(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "rLCWMJfLNx9B"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/skin_dataset/skin Disease Dataset/kaggle\""
      ],
      "metadata": {
        "id": "oi6VMZvTNy3M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1bf26e94-92fa-4409-fb57-eb539e094d57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  train_balanced  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "lLM6A7mnOdAd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/train_balanced\", transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(\"/content/skin_dataset/skin Disease Dataset/kaggle/val\", transform=val_transforms)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=2)\n",
        "\n",
        "NUM_CLASSES = 6"
      ],
      "metadata": {
        "id": "cnOmJeChOmNy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "model_rn = resnet50(weights=weights)\n",
        "model_rn.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(model_rn.fc.in_features, 1024),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(512, NUM_CLASSES)\n",
        ")\n",
        "\n",
        "for param in model_rn.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model_rn.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_rn = model_rn.to(DEVICE)"
      ],
      "metadata": {
        "id": "M_UlC1MBOrEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d36fae1a-330e-467b-c5f3-0e3fabbc80d3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model_rn.fc.parameters(),\n",
        "    lr=1e-5,\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "oJvbnkW3Q1X9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 5\n",
        "best_val_acc = 0\n",
        "counter = 0\n",
        "best_val_f1 = 0\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/resnet50_1.pth\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model_rn.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_rn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "        all_train_preds.extend(preds_np)\n",
        "        all_train_labels.extend(labels_np)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        batch_acc = (preds_np == labels_np).mean()\n",
        "        batch_precision = precision_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_recall = recall_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_f1 = f1_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "\n",
        "        sys.stdout.write(\n",
        "            f\"\\rEpoch {epoch+1}/{EPOCHS} | \"\n",
        "            f\"Batch {i}/{len(train_loader)} | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {batch_acc:.4f} | \"\n",
        "            f\"Prec: {batch_precision:.4f} | \"\n",
        "            f\"Rec: {batch_recall:.4f} | \"\n",
        "            f\"F1: {batch_f1:.4f}\"\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    model_rn.eval()\n",
        "\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model_rn(inputs)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
        "    val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary\")\n",
        "    print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f}\")\n",
        "    print(f\"Val   | Acc: {val_acc:.4f} | Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model_rn.state_dict(), MODEL_PATH)\n",
        "        counter = 0\n",
        "        print(\"Model improved. Saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement. Patience: {counter}/{PATIENCE}\")\n",
        "\n",
        "        if counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered\")"
      ],
      "metadata": {
        "id": "vrymTYEeSsmf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c8849edd-d90f-417b-b01b-12c1000c0927"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 | Batch 282/282 | Loss: 1.5666 | Acc: 0.5000 | Prec: 0.4417 | Rec: 0.4417 | F1: 0.3988\n",
            "\n",
            "Epoch 1 Summary\n",
            "Train | Loss: 1.6446 | Acc: 0.3258 | Prec: 0.3429 | Rec: 0.3258 | F1: 0.3172\n",
            "Val   | Acc: 0.5325 | Prec: 0.4850 | Rec: 0.5413 | F1: 0.4836\n",
            "Model improved. Saved.\n",
            "Epoch 2/25 | Batch 282/282 | Loss: 1.2438 | Acc: 0.5000 | Prec: 0.5000 | Rec: 0.4444 | F1: 0.4365\n",
            "\n",
            "Epoch 2 Summary\n",
            "Train | Loss: 1.3621 | Acc: 0.4861 | Prec: 0.4858 | Rec: 0.4861 | F1: 0.4841\n",
            "Val   | Acc: 0.5539 | Prec: 0.5077 | Rec: 0.5759 | F1: 0.5122\n",
            "Model improved. Saved.\n",
            "Epoch 3/25 | Batch 282/282 | Loss: 1.0475 | Acc: 0.6875 | Prec: 0.6806 | Rec: 0.7222 | F1: 0.6873\n",
            "\n",
            "Epoch 3 Summary\n",
            "Train | Loss: 1.2326 | Acc: 0.5292 | Prec: 0.5287 | Rec: 0.5292 | F1: 0.5279\n",
            "Val   | Acc: 0.5799 | Prec: 0.5268 | Rec: 0.5916 | F1: 0.5315\n",
            "Model improved. Saved.\n",
            "Epoch 4/25 | Batch 282/282 | Loss: 0.9919 | Acc: 0.5625 | Prec: 0.4583 | Rec: 0.6667 | F1: 0.5214\n",
            "\n",
            "Epoch 4 Summary\n",
            "Train | Loss: 1.1525 | Acc: 0.5591 | Prec: 0.5585 | Rec: 0.5591 | F1: 0.5579\n",
            "Val   | Acc: 0.6018 | Prec: 0.5463 | Rec: 0.6151 | F1: 0.5566\n",
            "Model improved. Saved.\n",
            "Epoch 5/25 | Batch 282/282 | Loss: 1.1879 | Acc: 0.5000 | Prec: 0.5278 | Rec: 0.3861 | F1: 0.4325\n",
            "\n",
            "Epoch 5 Summary\n",
            "Train | Loss: 1.1077 | Acc: 0.5751 | Prec: 0.5761 | Rec: 0.5751 | F1: 0.5747\n",
            "Val   | Acc: 0.6113 | Prec: 0.5548 | Rec: 0.6270 | F1: 0.5665\n",
            "Model improved. Saved.\n",
            "Epoch 6/25 | Batch 282/282 | Loss: 1.1547 | Acc: 0.3750 | Prec: 0.3306 | Rec: 0.4833 | F1: 0.3238\n",
            "\n",
            "Epoch 6 Summary\n",
            "Train | Loss: 1.0691 | Acc: 0.5861 | Prec: 0.5870 | Rec: 0.5861 | F1: 0.5858\n",
            "Val   | Acc: 0.6225 | Prec: 0.5664 | Rec: 0.6362 | F1: 0.5784\n",
            "Model improved. Saved.\n",
            "Epoch 7/25 | Batch 282/282 | Loss: 1.2851 | Acc: 0.3750 | Prec: 0.3889 | Rec: 0.3167 | F1: 0.3278\n",
            "\n",
            "Epoch 7 Summary\n",
            "Train | Loss: 1.0465 | Acc: 0.5952 | Prec: 0.5971 | Rec: 0.5952 | F1: 0.5953\n",
            "Val   | Acc: 0.6370 | Prec: 0.5758 | Rec: 0.6449 | F1: 0.5904\n",
            "Model improved. Saved.\n",
            "Epoch 8/25 | Batch 282/282 | Loss: 0.8261 | Acc: 0.7500 | Prec: 0.7778 | Rec: 0.7778 | F1: 0.7730\n",
            "\n",
            "Epoch 8 Summary\n",
            "Train | Loss: 1.0148 | Acc: 0.6100 | Prec: 0.6120 | Rec: 0.6100 | F1: 0.6101\n",
            "Val   | Acc: 0.6365 | Prec: 0.5766 | Rec: 0.6451 | F1: 0.5914\n",
            "Model improved. Saved.\n",
            "Epoch 9/25 | Batch 282/282 | Loss: 1.1796 | Acc: 0.5625 | Prec: 0.5972 | Rec: 0.6694 | F1: 0.6151\n",
            "\n",
            "Epoch 9 Summary\n",
            "Train | Loss: 0.9982 | Acc: 0.6170 | Prec: 0.6184 | Rec: 0.6170 | F1: 0.6168\n",
            "Val   | Acc: 0.6350 | Prec: 0.5786 | Rec: 0.6531 | F1: 0.5886\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 10/25 | Batch 282/282 | Loss: 0.7137 | Acc: 0.8125 | Prec: 0.8500 | Rec: 0.8778 | F1: 0.8278\n",
            "\n",
            "Epoch 10 Summary\n",
            "Train | Loss: 0.9804 | Acc: 0.6211 | Prec: 0.6234 | Rec: 0.6211 | F1: 0.6214\n",
            "Val   | Acc: 0.6406 | Prec: 0.5814 | Rec: 0.6562 | F1: 0.5964\n",
            "Model improved. Saved.\n",
            "Epoch 11/25 | Batch 282/282 | Loss: 1.2266 | Acc: 0.3750 | Prec: 0.3333 | Rec: 0.3750 | F1: 0.3082\n",
            "\n",
            "Epoch 11 Summary\n",
            "Train | Loss: 0.9647 | Acc: 0.6350 | Prec: 0.6372 | Rec: 0.6350 | F1: 0.6353\n",
            "Val   | Acc: 0.6444 | Prec: 0.5856 | Rec: 0.6614 | F1: 0.6014\n",
            "Model improved. Saved.\n",
            "Epoch 12/25 | Batch 282/282 | Loss: 1.4145 | Acc: 0.5625 | Prec: 0.6250 | Rec: 0.6556 | F1: 0.5528\n",
            "\n",
            "Epoch 12 Summary\n",
            "Train | Loss: 0.9547 | Acc: 0.6337 | Prec: 0.6357 | Rec: 0.6337 | F1: 0.6339\n",
            "Val   | Acc: 0.6505 | Prec: 0.5902 | Rec: 0.6648 | F1: 0.6067\n",
            "Model improved. Saved.\n",
            "Epoch 13/25 | Batch 282/282 | Loss: 1.1436 | Acc: 0.5625 | Prec: 0.6667 | Rec: 0.5111 | F1: 0.5619\n",
            "\n",
            "Epoch 13 Summary\n",
            "Train | Loss: 0.9467 | Acc: 0.6334 | Prec: 0.6355 | Rec: 0.6334 | F1: 0.6337\n",
            "Val   | Acc: 0.6513 | Prec: 0.5944 | Rec: 0.6676 | F1: 0.6096\n",
            "Model improved. Saved.\n",
            "Epoch 14/25 | Batch 282/282 | Loss: 0.6488 | Acc: 0.8125 | Prec: 0.7222 | Rec: 0.7028 | F1: 0.6910\n",
            "\n",
            "Epoch 14 Summary\n",
            "Train | Loss: 0.9360 | Acc: 0.6383 | Prec: 0.6411 | Rec: 0.6383 | F1: 0.6387\n",
            "Val   | Acc: 0.6582 | Prec: 0.5985 | Rec: 0.6689 | F1: 0.6164\n",
            "Model improved. Saved.\n",
            "Epoch 15/25 | Batch 282/282 | Loss: 1.1135 | Acc: 0.6250 | Prec: 0.6528 | Rec: 0.7222 | F1: 0.6278\n",
            "\n",
            "Epoch 15 Summary\n",
            "Train | Loss: 0.9258 | Acc: 0.6413 | Prec: 0.6429 | Rec: 0.6413 | F1: 0.6413\n",
            "Val   | Acc: 0.6526 | Prec: 0.5968 | Rec: 0.6699 | F1: 0.6083\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 16/25 | Batch 282/282 | Loss: 1.2702 | Acc: 0.5000 | Prec: 0.5000 | Rec: 0.6111 | F1: 0.4960\n",
            "\n",
            "Epoch 16 Summary\n",
            "Train | Loss: 0.9221 | Acc: 0.6463 | Prec: 0.6489 | Rec: 0.6463 | F1: 0.6467\n",
            "Val   | Acc: 0.6551 | Prec: 0.5963 | Rec: 0.6729 | F1: 0.6113\n",
            "No improvement. Patience: 2/5\n",
            "Epoch 17/25 | Batch 282/282 | Loss: 0.6918 | Acc: 0.7500 | Prec: 0.8167 | Rec: 0.8444 | F1: 0.7897\n",
            "\n",
            "Epoch 17 Summary\n",
            "Train | Loss: 0.9138 | Acc: 0.6467 | Prec: 0.6485 | Rec: 0.6467 | F1: 0.6468\n",
            "Val   | Acc: 0.6684 | Prec: 0.6134 | Rec: 0.6841 | F1: 0.6298\n",
            "Model improved. Saved.\n",
            "Epoch 18/25 | Batch 282/282 | Loss: 0.8440 | Acc: 0.6875 | Prec: 0.5972 | Rec: 0.6667 | F1: 0.6179\n",
            "\n",
            "Epoch 18 Summary\n",
            "Train | Loss: 0.9016 | Acc: 0.6472 | Prec: 0.6488 | Rec: 0.6472 | F1: 0.6470\n",
            "Val   | Acc: 0.6643 | Prec: 0.6090 | Rec: 0.6823 | F1: 0.6226\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 19/25 | Batch 282/282 | Loss: 1.0975 | Acc: 0.5625 | Prec: 0.5556 | Rec: 0.6230 | F1: 0.5101\n",
            "\n",
            "Epoch 19 Summary\n",
            "Train | Loss: 0.8949 | Acc: 0.6549 | Prec: 0.6578 | Rec: 0.6549 | F1: 0.6555\n",
            "Val   | Acc: 0.6681 | Prec: 0.6081 | Rec: 0.6835 | F1: 0.6246\n",
            "No improvement. Patience: 2/5\n",
            "Epoch 20/25 | Batch 282/282 | Loss: 1.0673 | Acc: 0.5625 | Prec: 0.5833 | Rec: 0.7421 | F1: 0.5796\n",
            "\n",
            "Epoch 20 Summary\n",
            "Train | Loss: 0.8898 | Acc: 0.6631 | Prec: 0.6646 | Rec: 0.6631 | F1: 0.6631\n",
            "Val   | Acc: 0.6597 | Prec: 0.6020 | Rec: 0.6802 | F1: 0.6177\n",
            "No improvement. Patience: 3/5\n",
            "Epoch 21/25 | Batch 282/282 | Loss: 1.1251 | Acc: 0.6875 | Prec: 0.7083 | Rec: 0.6111 | F1: 0.5968\n",
            "\n",
            "Epoch 21 Summary\n",
            "Train | Loss: 0.8860 | Acc: 0.6609 | Prec: 0.6629 | Rec: 0.6609 | F1: 0.6613\n",
            "Val   | Acc: 0.6745 | Prec: 0.6151 | Rec: 0.6899 | F1: 0.6303\n",
            "Model improved. Saved.\n",
            "Epoch 22/25 | Batch 282/282 | Loss: 1.3732 | Acc: 0.5625 | Prec: 0.6417 | Rec: 0.6667 | F1: 0.5500\n",
            "\n",
            "Epoch 22 Summary\n",
            "Train | Loss: 0.8723 | Acc: 0.6649 | Prec: 0.6667 | Rec: 0.6649 | F1: 0.6650\n",
            "Val   | Acc: 0.6750 | Prec: 0.6146 | Rec: 0.6886 | F1: 0.6339\n",
            "Model improved. Saved.\n",
            "Epoch 23/25 | Batch 282/282 | Loss: 0.9991 | Acc: 0.5625 | Prec: 0.6111 | Rec: 0.5556 | F1: 0.5222\n",
            "\n",
            "Epoch 23 Summary\n",
            "Train | Loss: 0.8664 | Acc: 0.6681 | Prec: 0.6695 | Rec: 0.6681 | F1: 0.6680\n",
            "Val   | Acc: 0.6737 | Prec: 0.6133 | Rec: 0.6862 | F1: 0.6305\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 24/25 | Batch 282/282 | Loss: 0.8499 | Acc: 0.6250 | Prec: 0.6667 | Rec: 0.5694 | F1: 0.5952\n",
            "\n",
            "Epoch 24 Summary\n",
            "Train | Loss: 0.8614 | Acc: 0.6671 | Prec: 0.6684 | Rec: 0.6671 | F1: 0.6671\n",
            "Val   | Acc: 0.6735 | Prec: 0.6172 | Rec: 0.6939 | F1: 0.6325\n",
            "No improvement. Patience: 2/5\n",
            "Epoch 25/25 | Batch 282/282 | Loss: 1.3434 | Acc: 0.4375 | Prec: 0.4722 | Rec: 0.3611 | F1: 0.3984\n",
            "\n",
            "Epoch 25 Summary\n",
            "Train | Loss: 0.8649 | Acc: 0.6670 | Prec: 0.6686 | Rec: 0.6670 | F1: 0.6671\n",
            "Val   | Acc: 0.6724 | Prec: 0.6119 | Rec: 0.6882 | F1: 0.6296\n",
            "No improvement. Patience: 3/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_rn.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "    {\"params\": model_rn.fc.parameters(), \"lr\": 1e-5},\n",
        "    {\"params\": model_rn.layer4.parameters(), \"lr\": 1e-6}\n",
        "], weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "Q6DDrrdE6w6S"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 5\n",
        "best_val_acc = 0\n",
        "counter = 0\n",
        "best_val_f1 = 0\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/resnet50_2.pth\"\n",
        "\n",
        "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    model_rn.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_rn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        preds_np = preds.detach().cpu().numpy()\n",
        "        labels_np = labels.detach().cpu().numpy()\n",
        "\n",
        "        all_train_preds.extend(preds_np)\n",
        "        all_train_labels.extend(labels_np)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        batch_acc = (preds_np == labels_np).mean()\n",
        "        batch_precision = precision_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_recall = recall_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "        batch_f1 = f1_score(labels_np, preds_np, average='macro', zero_division=0)\n",
        "\n",
        "        sys.stdout.write(\n",
        "            f\"\\rEpoch {epoch+1}/{EPOCHS} | \"\n",
        "            f\"Batch {i}/{len(train_loader)} | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {batch_acc:.4f} | \"\n",
        "            f\"Prec: {batch_precision:.4f} | \"\n",
        "            f\"Rec: {batch_recall:.4f} | \"\n",
        "            f\"F1: {batch_f1:.4f}\"\n",
        "        )\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "    train_loss = running_loss / len(train_dataset)\n",
        "    train_acc = np.mean(np.array(all_train_preds) == np.array(all_train_labels))\n",
        "    train_precision = precision_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
        "\n",
        "    model_rn.eval()\n",
        "\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model_rn(inputs)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = np.mean(np.array(val_preds) == np.array(val_labels))\n",
        "    val_precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary\")\n",
        "    print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f}\")\n",
        "    print(f\"Val   | Acc: {val_acc:.4f} | Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model_rn.state_dict(), MODEL_PATH)\n",
        "        counter = 0\n",
        "        print(\"Model improved. Saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"No improvement. Patience: {counter}/{PATIENCE}\")\n",
        "\n",
        "        if counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered\")"
      ],
      "metadata": {
        "id": "PA-641BT6tlV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb2dec51-b8c9-4648-fcf0-3ba172451bf2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Batch 282/282 | Loss: 0.7377 | Acc: 0.6875 | Prec: 0.6250 | Rec: 0.7083 | F1: 0.6063\n",
            "\n",
            "Epoch 1 Summary\n",
            "Train | Loss: 0.8510 | Acc: 0.6707 | Prec: 0.6725 | Rec: 0.6707 | F1: 0.6709\n",
            "Val   | Acc: 0.6862 | Prec: 0.6260 | Rec: 0.6961 | F1: 0.6454\n",
            "Model improved. Saved.\n",
            "Epoch 2/15 | Batch 282/282 | Loss: 0.6428 | Acc: 0.8125 | Prec: 0.8056 | Rec: 0.8333 | F1: 0.7889\n",
            "\n",
            "Epoch 2 Summary\n",
            "Train | Loss: 0.8459 | Acc: 0.6755 | Prec: 0.6770 | Rec: 0.6755 | F1: 0.6755\n",
            "Val   | Acc: 0.6798 | Prec: 0.6176 | Rec: 0.6911 | F1: 0.6337\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 3/15 | Batch 282/282 | Loss: 1.2845 | Acc: 0.5625 | Prec: 0.5694 | Rec: 0.5056 | F1: 0.4694\n",
            "\n",
            "Epoch 3 Summary\n",
            "Train | Loss: 0.8415 | Acc: 0.6757 | Prec: 0.6767 | Rec: 0.6757 | F1: 0.6755\n",
            "Val   | Acc: 0.6885 | Prec: 0.6292 | Rec: 0.6992 | F1: 0.6450\n",
            "No improvement. Patience: 2/5\n",
            "Epoch 4/15 | Batch 282/282 | Loss: 0.8357 | Acc: 0.6875 | Prec: 0.5833 | Rec: 0.5417 | F1: 0.5595\n",
            "\n",
            "Epoch 4 Summary\n",
            "Train | Loss: 0.8333 | Acc: 0.6772 | Prec: 0.6786 | Rec: 0.6772 | F1: 0.6772\n",
            "Val   | Acc: 0.6814 | Prec: 0.6206 | Rec: 0.6992 | F1: 0.6402\n",
            "No improvement. Patience: 3/5\n",
            "Epoch 5/15 | Batch 282/282 | Loss: 0.9870 | Acc: 0.5625 | Prec: 0.5556 | Rec: 0.6167 | F1: 0.5278\n",
            "\n",
            "Epoch 5 Summary\n",
            "Train | Loss: 0.8269 | Acc: 0.6837 | Prec: 0.6845 | Rec: 0.6837 | F1: 0.6836\n",
            "Val   | Acc: 0.6832 | Prec: 0.6254 | Rec: 0.7019 | F1: 0.6422\n",
            "No improvement. Patience: 4/5\n",
            "Epoch 6/15 | Batch 282/282 | Loss: 0.9084 | Acc: 0.6875 | Prec: 0.6806 | Rec: 0.7361 | F1: 0.6813\n",
            "\n",
            "Epoch 6 Summary\n",
            "Train | Loss: 0.8150 | Acc: 0.6887 | Prec: 0.6901 | Rec: 0.6887 | F1: 0.6887\n",
            "Val   | Acc: 0.6926 | Prec: 0.6312 | Rec: 0.7061 | F1: 0.6471\n",
            "Model improved. Saved.\n",
            "Epoch 7/15 | Batch 282/282 | Loss: 0.7730 | Acc: 0.6875 | Prec: 0.6944 | Rec: 0.6389 | F1: 0.6333\n",
            "\n",
            "Epoch 7 Summary\n",
            "Train | Loss: 0.8118 | Acc: 0.6870 | Prec: 0.6879 | Rec: 0.6870 | F1: 0.6868\n",
            "Val   | Acc: 0.6939 | Prec: 0.6335 | Rec: 0.7084 | F1: 0.6478\n",
            "Model improved. Saved.\n",
            "Epoch 8/15 | Batch 282/282 | Loss: 1.0012 | Acc: 0.6250 | Prec: 0.5000 | Rec: 0.5119 | F1: 0.4665\n",
            "\n",
            "Epoch 8 Summary\n",
            "Train | Loss: 0.8032 | Acc: 0.6921 | Prec: 0.6938 | Rec: 0.6921 | F1: 0.6921\n",
            "Val   | Acc: 0.6842 | Prec: 0.6256 | Rec: 0.7035 | F1: 0.6406\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 9/15 | Batch 282/282 | Loss: 1.0895 | Acc: 0.5625 | Prec: 0.5694 | Rec: 0.5278 | F1: 0.4813\n",
            "\n",
            "Epoch 9 Summary\n",
            "Train | Loss: 0.8027 | Acc: 0.6912 | Prec: 0.6921 | Rec: 0.6912 | F1: 0.6911\n",
            "Val   | Acc: 0.6982 | Prec: 0.6423 | Rec: 0.7183 | F1: 0.6570\n",
            "Model improved. Saved.\n",
            "Epoch 10/15 | Batch 282/282 | Loss: 0.8092 | Acc: 0.6875 | Prec: 0.6944 | Rec: 0.7083 | F1: 0.6762\n",
            "\n",
            "Epoch 10 Summary\n",
            "Train | Loss: 0.7850 | Acc: 0.7006 | Prec: 0.7014 | Rec: 0.7006 | F1: 0.7003\n",
            "Val   | Acc: 0.6954 | Prec: 0.6364 | Rec: 0.7127 | F1: 0.6513\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 11/15 | Batch 282/282 | Loss: 0.9654 | Acc: 0.6875 | Prec: 0.6667 | Rec: 0.7700 | F1: 0.6714\n",
            "\n",
            "Epoch 11 Summary\n",
            "Train | Loss: 0.7816 | Acc: 0.7038 | Prec: 0.7057 | Rec: 0.7038 | F1: 0.7039\n",
            "Val   | Acc: 0.6888 | Prec: 0.6302 | Rec: 0.7115 | F1: 0.6447\n",
            "No improvement. Patience: 2/5\n",
            "Epoch 12/15 | Batch 282/282 | Loss: 1.0529 | Acc: 0.6875 | Prec: 0.6389 | Rec: 0.6667 | F1: 0.6167\n",
            "\n",
            "Epoch 12 Summary\n",
            "Train | Loss: 0.7815 | Acc: 0.6989 | Prec: 0.6997 | Rec: 0.6989 | F1: 0.6987\n",
            "Val   | Acc: 0.7043 | Prec: 0.6449 | Rec: 0.7174 | F1: 0.6625\n",
            "Model improved. Saved.\n",
            "Epoch 13/15 | Batch 282/282 | Loss: 1.1373 | Acc: 0.5000 | Prec: 0.4167 | Rec: 0.4583 | F1: 0.4159\n",
            "\n",
            "Epoch 13 Summary\n",
            "Train | Loss: 0.7706 | Acc: 0.7083 | Prec: 0.7090 | Rec: 0.7083 | F1: 0.7079\n",
            "Val   | Acc: 0.7076 | Prec: 0.6485 | Rec: 0.7231 | F1: 0.6657\n",
            "Model improved. Saved.\n",
            "Epoch 14/15 | Batch 282/282 | Loss: 0.9877 | Acc: 0.6875 | Prec: 0.6333 | Rec: 0.5667 | F1: 0.5894\n",
            "\n",
            "Epoch 14 Summary\n",
            "Train | Loss: 0.7713 | Acc: 0.7060 | Prec: 0.7068 | Rec: 0.7060 | F1: 0.7057\n",
            "Val   | Acc: 0.7007 | Prec: 0.6407 | Rec: 0.7196 | F1: 0.6589\n",
            "No improvement. Patience: 1/5\n",
            "Epoch 15/15 | Batch 282/282 | Loss: 0.5857 | Acc: 0.7500 | Prec: 0.7639 | Rec: 0.8194 | F1: 0.7758\n",
            "\n",
            "Epoch 15 Summary\n",
            "Train | Loss: 0.7597 | Acc: 0.7089 | Prec: 0.7099 | Rec: 0.7089 | F1: 0.7087\n",
            "Val   | Acc: 0.7127 | Prec: 0.6538 | Rec: 0.7229 | F1: 0.6718\n",
            "Model improved. Saved.\n"
          ]
        }
      ]
    }
  ]
}